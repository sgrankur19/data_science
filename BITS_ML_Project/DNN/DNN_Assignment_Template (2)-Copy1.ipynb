{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Networks - Programming Assignment\n",
    "## Comparing Linear Models and Multi-Layer Perceptrons\n",
    "\n",
    "**Student Name:** ___________________  \n",
    "**Student ID:** ___________________  \n",
    "**Date:** ___________________\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è IMPORTANT INSTRUCTIONS\n",
    "\n",
    "1. **Complete ALL sections** marked with `TODO`\n",
    "2. **DO NOT modify** the `get_assignment_results()` function structure\n",
    "3. **Fill in all values accurately** - these will be auto-verified\n",
    "4. **After submission**, you'll receive a verification quiz based on YOUR results\n",
    "5. **Run all cells** before submitting (Kernel ‚Üí Restart & Run All)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "print('‚úì Libraries imported successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Dataset Selection and Loading\n",
    "\n",
    "**Requirements:**\n",
    "- ‚â•500 samples\n",
    "- ‚â•5 features\n",
    "- Public dataset (UCI/Kaggle)\n",
    "- Regression OR Classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Wine Quality\n",
      "Source: UCI Machine Learning Repository\n",
      "Samples: 1599, Features: 11\n",
      "Problem Type: regression\n",
      "Primary Metric: rmse\n"
     ]
    }
   ],
   "source": [
    "# TODO: Load your dataset\n",
    "# Example: data = pd.read_csv('your_dataset.csv')\n",
    "df = pd.read_csv(\"winequality-red.csv\", sep=';')\n",
    "\n",
    "# Dataset information (TODO: Fill these)\n",
    "dataset_name = \"Wine Quality\"  # e.g., \"Breast Cancer Wisconsin\"\n",
    "dataset_source = \"UCI Machine Learning Repository\"  # e.g., \"UCI ML Repository\"\n",
    "n_samples = 1599      # Total number of rows\n",
    "n_features = 11     # Number of features (excluding target)\n",
    "problem_type = \"regression\"  # \"regression\" or \"binary_classification\" or \"multiclass_classification\"\n",
    "\n",
    "# Problem statement (TODO: Write 2-3 sentences)\n",
    "problem_statement = \"\"\"\n",
    "Predicting sensory wine quality scores from physicochemical measurements of red Vinho Verde wines.\n",
    "This helps winemakers understand how acidity, alcohol, sulphates, and other chemical properties relate to perceived quality,\n",
    "which can guide process control and product improvement.\n",
    "\"\"\"\n",
    "\n",
    "# Primary evaluation metric (TODO: Fill this)\n",
    "primary_metric = \"rmse\"  # e.g., \"recall\", \"accuracy\", \"rmse\", \"r2\"\n",
    "\n",
    "# Metric justification (TODO: Write 2-3 sentences)\n",
    "metric_justification = \"\"\"\n",
    "Root Mean Squared Error (RMSE) directly measures the typical deviation between predicted and true quality scores in the\n",
    "same units as the target, making the error magnitude easy to interpret.‚Äã\n",
    "Since this is a numeric quality score with no dominant threshold of interest, minimizing overall prediction error is more\n",
    "important than optimizing classification-style metrics, so RMSE is an appropriate primary metric.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Dataset: {dataset_name}\")\n",
    "print(f\"Source: {dataset_source}\")\n",
    "print(f\"Samples: {n_samples}, Features: {n_features}\")\n",
    "print(f\"Problem Type: {problem_type}\")\n",
    "print(f\"Primary Metric: {primary_metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Data Preprocessing\n",
    "\n",
    "Preprocess your data:\n",
    "1. Handle missing values\n",
    "2. Encode categorical variables\n",
    "3. Split into train/test sets\n",
    "4. Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 1279\n",
      "Test samples: 320\n",
      "Split ratio: 80.0%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Preprocess your data\n",
    "X = df.drop('quality', axis=1).values\n",
    "y = df['quality'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fill these after preprocessing\n",
    "train_samples = 1279       # Number of training samples\n",
    "test_samples = 320        # Number of test samples\n",
    "train_test_ratio = train_samples / (train_samples + test_samples)  # e.g., 0.8 for 80-20 split\n",
    "\n",
    "print(f\"Train samples: {train_samples}\")\n",
    "print(f\"Test samples: {test_samples}\")\n",
    "print(f\"Split ratio: {train_test_ratio:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Baseline Model Implementation\n",
    "\n",
    "Implement from scratch (NO sklearn models!):\n",
    "- Linear Regression (for regression)\n",
    "- Logistic Regression (for binary classification)\n",
    "- Softmax Regression (for multiclass classification)\n",
    "\n",
    "**Must include:**\n",
    "- Forward pass (prediction)\n",
    "- Loss computation\n",
    "- Gradient computation\n",
    "- Gradient descent loop\n",
    "- Loss tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Baseline model class defined\n"
     ]
    }
   ],
   "source": [
    "class BaselineModel:\n",
    "    \"\"\"\n",
    "    Baseline linear model with gradient descent\n",
    "    Implemented here as Linear Regression (MSE loss)\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.loss_history = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Gradient descent training\n",
    "        \n",
    "        Steps:\n",
    "        1. Initialize weights and bias\n",
    "        2. For each iteration:\n",
    "           a. Compute predictions (forward pass)\n",
    "           b. Compute loss (MSE)\n",
    "           c. Compute gradients\n",
    "           d. Update weights and bias\n",
    "           e. Store loss in self.loss_history\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # 1. Initialize parameters\n",
    "        self.weights = np.zeros(n_features)   # shape: (n_features,)\n",
    "        self.bias = 0.0\n",
    "        \n",
    "        # Ensure y is 1D\n",
    "        y = y.ravel()\n",
    "        \n",
    "        # 2. Gradient descent loop\n",
    "        for _ in range(self.n_iterations):\n",
    "            # a. Forward pass\n",
    "            y_pred = np.dot(X, self.weights) + self.bias   # (n_samples,)\n",
    "            \n",
    "            # b. Loss (Mean Squared Error)\n",
    "            errors = y_pred - y                            # (n_samples,)\n",
    "            loss = np.mean(errors ** 2)\n",
    "            \n",
    "            # c. Gradients of MSE w.r.t. weights and bias\n",
    "            dw = (2 / n_samples) * np.dot(X.T, errors)     # (n_features,)\n",
    "            db = (2 / n_samples) * np.sum(errors)          # scalar\n",
    "            \n",
    "            # d. Parameter update\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias    -= self.lr * db\n",
    "            \n",
    "            # e. Record loss\n",
    "            self.loss_history.append(loss)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        For regression: return linear outputs.\n",
    "        \"\"\"\n",
    "        return np.dot(X, self.weights) + self.bias\n",
    "\n",
    "print(\"‚úì Baseline model class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training baseline model...\n",
      "‚úì Baseline training completed in 0.04s\n",
      "‚úì Loss decreased from 32.2791 to 0.4242\n"
     ]
    }
   ],
   "source": [
    "# Train baseline model\n",
    "print(\"Training baseline model...\")\n",
    "baseline_start_time = time.time()\n",
    "\n",
    "# Initialize and train your baseline model\n",
    "baseline_model = BaselineModel(learning_rate=0.01, n_iterations=1000)\n",
    "baseline_model.fit(X_train_scaled, y_train)  # Uses scaled features for better convergence\n",
    "\n",
    "# Make predictions on test set\n",
    "baseline_predictions = baseline_model.predict(X_test_scaled)\n",
    "\n",
    "baseline_training_time = time.time() - baseline_start_time\n",
    "print(f\"‚úì Baseline training completed in {baseline_training_time:.2f}s\")\n",
    "print(f\"‚úì Loss decreased from {baseline_model.loss_history[0]:.4f} to {baseline_model.loss_history[-1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Multi-Layer Perceptron Implementation\n",
    "\n",
    "Implement MLP from scratch with:\n",
    "- At least 1 hidden layer\n",
    "- ReLU activation for hidden layers\n",
    "- Appropriate output activation\n",
    "- Forward propagation\n",
    "- Backward propagation\n",
    "- Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì MLP class defined\n"
     ]
    }
   ],
   "source": [
    "class MLP:\n",
    "    \"\"\"\n",
    "    Multi-Layer Perceptron implemented from scratch\n",
    "    \"\"\"\n",
    "    def __init__(self, architecture, learning_rate=0.01, n_iterations=1000):\n",
    "        self.architecture = architecture\n",
    "        self.lr = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.parameters = {}\n",
    "        self.loss_history = []\n",
    "        self.cache = {}\n",
    "    \n",
    "    def initialize_parameters(self):\n",
    "        \"\"\"Xavier initialization for weights, zeros for biases\"\"\"\n",
    "        np.random.seed(42)\n",
    "        for l in range(1, len(self.architecture)):\n",
    "            n_l, n_l1 = self.architecture[l], self.architecture[l-1]\n",
    "            self.parameters[f'W{l}'] = np.random.randn(n_l, n_l1) * np.sqrt(2.0 / n_l1)\n",
    "            self.parameters[f'b{l}'] = np.zeros((n_l, 1))\n",
    "    \n",
    "    def relu(self, Z):\n",
    "        \"\"\"ReLU activation function\"\"\"\n",
    "        return np.maximum(0, Z)\n",
    "    \n",
    "    def relu_derivative(self, Z):\n",
    "        \"\"\"ReLU derivative\"\"\"\n",
    "        return (Z > 0).astype(float)\n",
    "    \n",
    "    def sigmoid(self, Z):\n",
    "        \"\"\"Sigmoid activation (for binary classification output)\"\"\"\n",
    "        return 1 / (1 + np.exp(-np.clip(Z, -500, 500)))\n",
    "    \n",
    "    def forward_propagation(self, X):\n",
    "        \"\"\"Fixed forward pass with proper bias broadcasting\"\"\"\n",
    "        self.cache['A0'] = X.reshape(-1, self.architecture[0])  # Ensure (m, n_input)\n",
    "        \n",
    "        for l in range(1, len(self.architecture)):\n",
    "            # Z = W @ A_prev + b  (broadcast b across samples)\n",
    "            Z = self.parameters[f'W{l}'] @ self.cache[f'A{l-1}'] + self.parameters[f'b{l}']\n",
    "            self.cache[f'Z{l}'] = Z\n",
    "            \n",
    "            if l == len(self.architecture) - 1:  # Output layer\n",
    "                A = Z  # Linear activation for regression\n",
    "            else:  # Hidden layers\n",
    "                A = self.relu(Z)\n",
    "            \n",
    "            self.cache[f'A{l}'] = A\n",
    "        \n",
    "        return self.cache[f'A{len(self.architecture)-1}']\n",
    "  \n",
    "\n",
    "    def backward_propagation(self, X, y):\n",
    "        \"\"\"Corrected backward pass with proper dimension handling\"\"\"\n",
    "        m = X.shape[0]\n",
    "        L = len(self.architecture) - 1\n",
    "        grads = {}\n",
    "        \n",
    "        # Output layer gradients (MSE loss)\n",
    "        y_pred = self.cache[f'A{L}']  # (m, 1)\n",
    "        dZ = 2 * (y_pred - y) / m    # (m, 1)\n",
    "        \n",
    "        grads[f'dW{L}'] = (1/m) * (dZ @ self.cache[f'A{L-1}'].T)  # (1, n[L-1])\n",
    "        grads[f'db{L}'] = np.sum(dZ, axis=0, keepdims=True)       # (1, 1)\n",
    "        \n",
    "        # Backpropagate through hidden layers\n",
    "        for l in reversed(range(1, L)):\n",
    "            # dZ[l] = dA[l] * g'(Z[l]) where dA[l] = W[l+1].T @ dZ[l+1]\n",
    "            dA = grads[f'dW{l+1}'].T @ dZ  # (n[l], m) @ (m, n[l+1]) -> (n[l], 1)? Wait no\n",
    "            \n",
    "            # CORRECT: dZ[l] = (W[l+1].T @ dZ[l+1]) * g'(Z[l])\n",
    "            dZ = (self.parameters[f'W{l+1}'].T @ dZ) * self.relu_derivative(self.cache[f'Z{l}'])\n",
    "            \n",
    "            grads[f'dW{l}'] = (1/m) * (dZ @ self.cache[f'A{l-1}'].T)\n",
    "            grads[f'db{l}'] = np.sum(dZ, axis=0, keepdims=True)\n",
    "        \n",
    "        return grads\n",
    "\n",
    "    \n",
    "    def update_parameters(self, grads):\n",
    "        \"\"\"Update all parameters using gradient descent\"\"\"\n",
    "        L = len(self.architecture) - 1\n",
    "        for l in range(1, L+1):\n",
    "            self.parameters[f'W{l}'] -= self.lr * grads[f'dW{l}']\n",
    "            self.parameters[f'b{l}'] -= self.lr * grads[f'db{l}']\n",
    "    \n",
    "    def compute_loss(self, y_pred, y_true):\n",
    "        \"\"\"MSE loss for regression\"\"\"\n",
    "        return np.mean((y_pred - y_true) ** 2)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fixed training loop with proper input shapes\"\"\"\n",
    "        self.initialize_parameters()\n",
    "        \n",
    "        # Ensure proper shapes\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "        y = y.reshape(-1, 1)  # (m, 1)\n",
    "        \n",
    "        for i in range(self.n_iterations):\n",
    "            # Forward\n",
    "            y_pred = self.forward_propagation(X)\n",
    "            \n",
    "            # Loss\n",
    "            loss = self.compute_loss(y_pred, y)\n",
    "            self.loss_history.append(loss)\n",
    "            \n",
    "            # Backward + Update\n",
    "            grads = self.backward_propagation(X, y)\n",
    "            self.update_parameters(grads)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Prediction using forward propagation\"\"\"\n",
    "        return self.forward_propagation(X)\n",
    "\n",
    "print(\"‚úì MLP class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1279 is different from 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m mlp_architecture = [\u001b[32m11\u001b[39m, \u001b[32m16\u001b[39m, \u001b[32m8\u001b[39m, \u001b[32m1\u001b[39m]  \n\u001b[32m      7\u001b[39m mlp_model = MLP(architecture=mlp_architecture, learning_rate=\u001b[32m0.001\u001b[39m, n_iterations=\u001b[32m2000\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mmlp_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Make predictions on test set\u001b[39;00m\n\u001b[32m     11\u001b[39m mlp_predictions = mlp_model.predict(X_test_scaled)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 104\u001b[39m, in \u001b[36mMLP.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    100\u001b[39m y = y.reshape(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# (m, 1)\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.n_iterations):\n\u001b[32m    103\u001b[39m     \u001b[38;5;66;03m# Forward\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     y_pred = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward_propagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     \u001b[38;5;66;03m# Loss\u001b[39;00m\n\u001b[32m    107\u001b[39m     loss = \u001b[38;5;28mself\u001b[39m.compute_loss(y_pred, y)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mMLP.forward_propagation\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28mself\u001b[39m.cache[\u001b[33m'\u001b[39m\u001b[33mA0\u001b[39m\u001b[33m'\u001b[39m] = X  \u001b[38;5;66;03m# (m, n[0])\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.architecture)):\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# Linear transformation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     Z = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mW\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43ml\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mA\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43ml\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m + \u001b[38;5;28mself\u001b[39m.parameters[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mb\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ml\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m]\n\u001b[32m     43\u001b[39m     \u001b[38;5;28mself\u001b[39m.cache[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mZ\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ml\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m] = Z\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m l == \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.architecture) - \u001b[32m1\u001b[39m:  \u001b[38;5;66;03m# Output layer (regression)\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1279 is different from 11)"
     ]
    }
   ],
   "source": [
    "# Train MLP\n",
    "print(\"Training MLP...\")\n",
    "mlp_start_time = time.time()\n",
    "\n",
    "# Define architecture: [11 input features, 16 hidden, 8 hidden, 1 output]\n",
    "mlp_architecture = [11, 16, 8, 1]  \n",
    "mlp_model = MLP(architecture=mlp_architecture, learning_rate=0.001, n_iterations=2000)\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "mlp_predictions = mlp_model.predict(X_test_scaled)\n",
    "\n",
    "mlp_training_time = time.time() - mlp_start_time\n",
    "print(f\"‚úì MLP training completed in {mlp_training_time:.2f}s\")\n",
    "print(f\"‚úì Loss decreased from {mlp_model.loss_history[0]:.4f} to {mlp_model.loss_history[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Evaluation and Metrics\n",
    "\n",
    "Calculate appropriate metrics for your problem type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred, problem_type):\n",
    "    \"\"\"\n",
    "    TODO: Calculate appropriate metrics based on problem type\n",
    "    \n",
    "    For regression: MSE, RMSE, MAE, R¬≤\n",
    "    For classification: Accuracy, Precision, Recall, F1\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    if problem_type == \"regression\":\n",
    "        # TODO: Calculate regression metrics\n",
    "        pass\n",
    "    elif problem_type in [\"binary_classification\", \"multiclass_classification\"]:\n",
    "        # TODO: Calculate classification metrics\n",
    "        pass\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calculate metrics for both models\n",
    "# baseline_metrics = calculate_metrics(y_test, baseline_predictions, problem_type)\n",
    "# mlp_metrics = calculate_metrics(y_test, mlp_predictions, problem_type)\n",
    "\n",
    "print(\"Baseline Model Performance:\")\n",
    "# print(baseline_metrics)\n",
    "\n",
    "print(\"\\nMLP Model Performance:\")\n",
    "# print(mlp_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Visualization\n",
    "\n",
    "Create visualizations:\n",
    "1. Training loss curves\n",
    "2. Performance comparison\n",
    "3. Additional domain-specific plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Training loss curves\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "# TODO: Plot baseline loss\n",
    "# plt.plot(baseline_model.loss_history, label='Baseline', color='blue')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Baseline Model - Training Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# TODO: Plot MLP loss\n",
    "# plt.plot(mlp_model.loss_history, label='MLP', color='red')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('MLP Model - Training Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Performance comparison bar chart\n",
    "# TODO: Create bar chart comparing key metrics between models\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Example:\n",
    "# metrics = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "# baseline_scores = [baseline_metrics[m] for m in metrics]\n",
    "# mlp_scores = [mlp_metrics[m] for m in metrics]\n",
    "# \n",
    "# x = np.arange(len(metrics))\n",
    "# width = 0.35\n",
    "# \n",
    "# plt.bar(x - width/2, baseline_scores, width, label='Baseline')\n",
    "# plt.bar(x + width/2, mlp_scores, width, label='MLP')\n",
    "# plt.xlabel('Metrics')\n",
    "# plt.ylabel('Score')\n",
    "# plt.title('Model Performance Comparison')\n",
    "# plt.xticks(x, metrics)\n",
    "# plt.legend()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Analysis and Discussion\n",
    "\n",
    "Write your analysis (minimum 200 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_text = \"\"\"\n",
    "TODO: Write your analysis here (minimum 200 words)\n",
    "\n",
    "Address these questions:\n",
    "1. Which model performed better and by how much?\n",
    "2. Why do you think one model outperformed the other?\n",
    "3. What was the computational cost difference (training time)?\n",
    "4. Any surprising findings or challenges you faced?\n",
    "5. What insights did you gain about neural networks vs linear models?\n",
    "\n",
    "Write your thoughtful analysis here. Be specific and reference your actual results.\n",
    "Compare the metrics, discuss the trade-offs, and explain what you learned.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Analysis word count: {len(analysis_text.split())} words\")\n",
    "if len(analysis_text.split()) < 200:\n",
    "    print(\"‚ö†Ô∏è  Warning: Analysis should be at least 200 words\")\n",
    "else:\n",
    "    print(\"‚úì Analysis meets word count requirement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## ‚≠ê REQUIRED: Structured Output Function\n",
    "\n",
    "### **DO NOT MODIFY THE STRUCTURE BELOW**\n",
    "\n",
    "This function will be called by the auto-grader. Fill in all values accurately based on your actual results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assignment_results():\n",
    "    \"\"\"\n",
    "    Return all assignment results in structured format.\n",
    "    \n",
    "    CRITICAL: Fill in ALL values based on your actual results!\n",
    "    This will be automatically extracted and validated.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate loss convergence flags\n",
    "    baseline_initial_loss = 0.0  # TODO: baseline_model.loss_history[0]\n",
    "    baseline_final_loss = 0.0    # TODO: baseline_model.loss_history[-1]\n",
    "    mlp_initial_loss = 0.0       # TODO: mlp_model.loss_history[0]\n",
    "    mlp_final_loss = 0.0         # TODO: mlp_model.loss_history[-1]\n",
    "    \n",
    "    results = {\n",
    "        # ===== Dataset Information =====\n",
    "        'dataset_name': dataset_name,\n",
    "        'dataset_source': dataset_source,\n",
    "        'n_samples': n_samples,\n",
    "        'n_features': n_features,\n",
    "        'problem_type': problem_type,\n",
    "        'problem_statement': problem_statement,\n",
    "        \n",
    "        # ===== Evaluation Setup =====\n",
    "        'primary_metric': primary_metric,\n",
    "        'metric_justification': metric_justification,\n",
    "        'train_samples': train_samples,\n",
    "        'test_samples': test_samples,\n",
    "        'train_test_ratio': train_test_ratio,\n",
    "        \n",
    "        # ===== Baseline Model Results =====\n",
    "        'baseline_model': {\n",
    "            'model_type': '',  # 'linear_regression', 'logistic_regression', or 'softmax_regression'\n",
    "            'learning_rate': 0.0,\n",
    "            'n_iterations': 0,\n",
    "            'initial_loss': baseline_initial_loss,\n",
    "            'final_loss': baseline_final_loss,\n",
    "            'training_time_seconds': baseline_training_time,\n",
    "            \n",
    "            # Metrics (fill based on your problem type)\n",
    "            'test_accuracy': 0.0,      # For classification\n",
    "            'test_precision': 0.0,     # For classification\n",
    "            'test_recall': 0.0,        # For classification\n",
    "            'test_f1': 0.0,            # For classification\n",
    "            'test_mse': 0.0,           # For regression\n",
    "            'test_rmse': 0.0,          # For regression\n",
    "            'test_mae': 0.0,           # For regression\n",
    "            'test_r2': 0.0,            # For regression\n",
    "        },\n",
    "        \n",
    "        # ===== MLP Model Results =====\n",
    "        'mlp_model': {\n",
    "            'architecture': mlp_architecture,\n",
    "            'n_hidden_layers': len(mlp_architecture) - 2 if len(mlp_architecture) > 0 else 0,\n",
    "            'total_parameters': 0,     # TODO: Calculate total weights + biases\n",
    "            'learning_rate': 0.0,\n",
    "            'n_iterations': 0,\n",
    "            'initial_loss': mlp_initial_loss,\n",
    "            'final_loss': mlp_final_loss,\n",
    "            'training_time_seconds': mlp_training_time,\n",
    "            \n",
    "            # Metrics\n",
    "            'test_accuracy': 0.0,\n",
    "            'test_precision': 0.0,\n",
    "            'test_recall': 0.0,\n",
    "            'test_f1': 0.0,\n",
    "            'test_mse': 0.0,\n",
    "            'test_rmse': 0.0,\n",
    "            'test_mae': 0.0,\n",
    "            'test_r2': 0.0,\n",
    "        },\n",
    "        \n",
    "        # ===== Comparison =====\n",
    "        'improvement': 0.0,            # MLP primary_metric - baseline primary_metric\n",
    "        'improvement_percentage': 0.0,  # (improvement / baseline) * 100\n",
    "        'baseline_better': False,       # True if baseline outperformed MLP\n",
    "        \n",
    "        # ===== Analysis =====\n",
    "        'analysis': analysis_text,\n",
    "        'analysis_word_count': len(analysis_text.split()),\n",
    "        \n",
    "        # ===== Loss Convergence Flags =====\n",
    "        'baseline_loss_decreased': baseline_final_loss < baseline_initial_loss,\n",
    "        'mlp_loss_decreased': mlp_final_loss < mlp_initial_loss,\n",
    "        'baseline_converged': False,  # Optional: True if converged\n",
    "        'mlp_converged': False,\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Your Output\n",
    "\n",
    "Run this cell to verify your results dictionary is complete and properly formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the output\n",
    "import json\n",
    "\n",
    "try:\n",
    "    results = get_assignment_results()\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"ASSIGNMENT RESULTS SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(json.dumps(results, indent=2, default=str))\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing = []\n",
    "    def check_dict(d, prefix=\"\"):\n",
    "        for k, v in d.items():\n",
    "            if isinstance(v, dict):\n",
    "                check_dict(v, f\"{prefix}{k}.\")\n",
    "            elif (v == 0 or v == \"\" or v == 0.0 or v == []) and \\\n",
    "                 k not in ['improvement', 'improvement_percentage', 'baseline_better', \n",
    "                          'baseline_converged', 'mlp_converged', 'total_parameters',\n",
    "                          'test_accuracy', 'test_precision', 'test_recall', 'test_f1',\n",
    "                          'test_mse', 'test_rmse', 'test_mae', 'test_r2']:\n",
    "                missing.append(f\"{prefix}{k}\")\n",
    "    \n",
    "    check_dict(results)\n",
    "    \n",
    "    if missing:\n",
    "        print(f\"‚ö†Ô∏è  Warning: {len(missing)} fields still need to be filled:\")\n",
    "        for m in missing[:15]:  # Show first 15\n",
    "            print(f\"  - {m}\")\n",
    "        if len(missing) > 15:\n",
    "            print(f\"  ... and {len(missing)-15} more\")\n",
    "    else:\n",
    "        print(\"‚úÖ All required fields are filled!\")\n",
    "        print(\"\\nüéâ You're ready to submit!\")\n",
    "        print(\"\\nNext steps:\")\n",
    "        print(\"1. Kernel ‚Üí Restart & Clear Output\")\n",
    "        print(\"2. Kernel ‚Üí Restart & Run All\")\n",
    "        print(\"3. Verify no errors\")\n",
    "        print(\"4. Save notebook\")\n",
    "        print(\"5. Rename as: YourStudentID_assignment.ipynb\")\n",
    "        print(\"6. Submit to LMS\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in get_assignment_results(): {str(e)}\")\n",
    "    print(\"\\nPlease fix the errors above before submitting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üì§ Before Submitting - Final Checklist\n",
    "\n",
    "- [ ] **All TODO sections completed**\n",
    "- [ ] **Both models implemented from scratch** (no sklearn models!)\n",
    "- [ ] **get_assignment_results() function filled accurately**\n",
    "- [ ] **Loss decreases for both models**\n",
    "- [ ] **Analysis ‚â• 200 words**\n",
    "- [ ] **All cells run without errors** (Restart & Run All)\n",
    "- [ ] **Visualizations created**\n",
    "- [ ] **File renamed correctly**: YourStudentID_assignment.ipynb\n",
    "\n",
    "---\n",
    "\n",
    "## ‚è≠Ô∏è What Happens Next\n",
    "\n",
    "After submission:\n",
    "1. ‚úÖ Your notebook will be **auto-graded** (executes automatically)\n",
    "2. ‚úÖ You'll receive a **verification quiz** (10 questions, 5 minutes)\n",
    "3. ‚úÖ Quiz questions based on **YOUR specific results**\n",
    "4. ‚úÖ Final score released after quiz validation\n",
    "\n",
    "**The verification quiz ensures you actually ran your code!**\n",
    "\n",
    "---\n",
    "\n",
    "**Good luck! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
